{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Import necessary libraries**"
      ],
      "metadata": {
        "id": "gH9yT3CtqOJQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fI-eT3SEpKy7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import numpy.core\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, TimeDistributed, Masking, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Positional embedding class**"
      ],
      "metadata": {
        "id": "0rtRt5iOqM8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(Layer):\n",
        "    def __init__(self):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "    def get_angles(self, pos, i, d_model):\n",
        "        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "        return pos * angle_rates\n",
        "\n",
        "    def call(self, seq_len, d_model):\n",
        "        #seq_len = inputs.shape[1]\n",
        "        #d_model = inputs.shape[2]\n",
        "        angles = self.get_angles(np.arange(seq_len)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model)\n",
        "        angles[:, 0::2] = np.sin(angles[:, 0::2])\n",
        "        angles[:, 1::2] = np.cos(angles[:, 1::2])\n",
        "        pos_encoding = angles[np.newaxis, ...]\n",
        "        return tf.cast(pos_encoding, tf.float32)"
      ],
      "metadata": {
        "id": "MCy6c4VApcZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder**"
      ],
      "metadata": {
        "id": "9reOuQuJrXe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, mask, dropout=0):\n",
        "    # Self-attention\n",
        "    attention, scores = MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(inputs, inputs, attention_mask=mask, return_attention_scores=True)\n",
        "    attention = Dropout(dropout)(attention)\n",
        "    out1 = LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "    # Feed-forward network\n",
        "    ffn = Dense(ff_dim, activation='relu')(out1)\n",
        "    ffn = Dense(inputs.shape[-1])(ffn)\n",
        "    ffn = Dropout(dropout)(ffn)\n",
        "    ffn = LayerNormalization(epsilon=1e-6)(out1 + ffn)\n",
        "    ffn = Dense(ff_dim)(ffn)\n",
        "    return ffn\n"
      ],
      "metadata": {
        "id": "LddXWhQApcbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_attention_block(\n",
        "    A, B, C,\n",
        "    head_size, num_heads,\n",
        "    dropout=0,\n",
        "    mask_A=None,\n",
        "    mask_B=None,\n",
        "    mask_C=None,\n",
        "):\n",
        "    # ---- A attends to others ----\n",
        "    A_B, A_B_score = MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(\n",
        "        A, B, attention_mask=mask_A, return_attention_scores=True)\n",
        "    A_C, A_C_score = MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(\n",
        "        A, C, attention_mask=mask_A, return_attention_scores=True)\n",
        "\n",
        "    A_out = LayerNormalization(epsilon=1e-6)(A + Dropout(dropout)(A_B) + Dropout(dropout)(A_C))\n",
        "\n",
        "    # ---- B attends to others ----\n",
        "    B_A, B_A_score = MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(\n",
        "        B, A, attention_mask=mask_B, return_attention_scores=True)\n",
        "    B_C, B_C_score = MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(\n",
        "        B, C, attention_mask=mask_B, return_attention_scores=True)\n",
        "\n",
        "    B_out = LayerNormalization(epsilon=1e-6)(B + Dropout(dropout)(B_A) + Dropout(dropout)(B_C))\n",
        "\n",
        "    # ---- C attends to others ----\n",
        "    C_A, C_A_score = MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(\n",
        "        C, A, attention_mask=mask_C, return_attention_scores=True)\n",
        "    C_B, C_B_score = MultiHeadAttention(num_heads=num_heads, key_dim=head_size)(\n",
        "        C, B, attention_mask=mask_C, return_attention_scores=True)\n",
        "\n",
        "    C_out = LayerNormalization(epsilon=1e-6)(C + Dropout(dropout)(C_A) + Dropout(dropout)(C_B))\n",
        "\n",
        "    return (\n",
        "        A_out, B_out, C_out,\n",
        "        {\n",
        "            \"A_B\": A_B_score, \"A_C\": A_C_score,\n",
        "            \"B_A\": B_A_score, \"B_C\": B_C_score,\n",
        "            \"C_A\": C_A_score, \"C_B\": C_B_score,\n",
        "        }\n",
        "    )\n"
      ],
      "metadata": {
        "id": "0ApDL2sSpceJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decoder**"
      ],
      "metadata": {
        "id": "hpj8NJmJsBQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_decoder(inputs, encoder_outputs, head_size, num_heads, ff_dim, dropout=0):#, encoder_mask=None):\n",
        "    # Masked self-attention (causal attention)\n",
        "    attention = MultiHeadAttention(num_heads=num_heads, key_dim=head_size)\n",
        "    attention_out = attention(inputs, inputs, use_causal_mask=True)\n",
        "    attention_out = Dropout(dropout)(attention_out)\n",
        "    out1 = LayerNormalization(epsilon=1e-6)(inputs + attention_out)\n",
        "\n",
        "    # Cross-attention\n",
        "    cross_attention = MultiHeadAttention(num_heads=num_heads, key_dim=head_size)\n",
        "    attention_out = cross_attention(out1, encoder_outputs)#, attention_mask=encoder_mask)\n",
        "    attention_out = Dropout(dropout)(attention_out)\n",
        "    out2 = LayerNormalization(epsilon=1e-6)(out1 + attention_out)\n",
        "\n",
        "    # Feed-forward\n",
        "    ffn = Dense(ff_dim, activation='relu')\n",
        "    ffn_out = ffn(out2)\n",
        "    ffn_out = Dense(inputs.shape[-1])(ffn_out)\n",
        "    ffn_out = Dropout(dropout)(ffn_out)\n",
        "    out3 = LayerNormalization(epsilon=1e-6)(out2 + ffn_out)\n",
        "\n",
        "    return out3\n"
      ],
      "metadata": {
        "id": "toWR5eXtpcgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build Cross-attentional Transformer-AutoRegressive**"
      ],
      "metadata": {
        "id": "CM1TM_D-sOLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_transformer_model(max_seq_length, dim_a, dim_b, dim_c, head_size, num_heads, ff_dim, dropout=0):\n",
        "    pe = PositionalEncoding()\n",
        "    # Encoder input\n",
        "    encoder_input_a = Input(shape=(max_seq_length, dim_a))\n",
        "    encoder_input_a += pe(max_seq_length, dim_a)\n",
        "    encoder_input_b = Input(shape=(max_seq_length, dim_b))\n",
        "    encoder_input_b += pe(max_seq_length, dim_b)\n",
        "    encoder_input_c = Input(shape=(max_seq_length, dim_c))\n",
        "    encoder_input_c += pe(max_seq_length, dim_c)\n",
        "\n",
        "\n",
        "    # Masking to handle variable length sequences and features\n",
        "    time_step_mask_a = tf.math.not_equal(encoder_input_a[:, :, 0], -50.0)\n",
        "    time_step_mask_a = tf.cast(time_step_mask_a[:, None, None, :], tf.float32)\n",
        "    time_step_mask_b = tf.math.not_equal(encoder_input_b[:, :, 0], -50.0)\n",
        "    time_step_mask_b = tf.cast(time_step_mask_b[:, None, None, :], tf.float32)\n",
        "    time_step_mask_c = tf.math.not_equal(encoder_input_c[:, :, 0], -50.0)\n",
        "    time_step_mask_c = tf.cast(time_step_mask_c[:, None, None, :], tf.float32)\n",
        "\n",
        "    # Encoder\n",
        "    encoder_output_a = encoder_input_a\n",
        "    encoder_output_b = encoder_input_b\n",
        "    encoder_output_c = encoder_input_c\n",
        "\n",
        "    # Self-attention\n",
        "    encoder_output_a = transformer_encoder(encoder_output_a, head_size, num_heads, ff_dim, time_step_mask_a, dropout)\n",
        "    encoder_output_b = transformer_encoder(encoder_output_b, head_size, num_heads, ff_dim, time_step_mask_b, dropout)\n",
        "    encoder_output_c = transformer_encoder(encoder_output_c, head_size, num_heads, ff_dim, time_step_mask_c, dropout)\n",
        "\n",
        "\n",
        "    # Cross-attention between modalities\n",
        "    cross_a, cross_b, cross_c, _  = cross_attention_block(encoder_output_a, encoder_output_b, encoder_output_c, head_size, num_heads, dropout,\n",
        "                                                                           time_step_mask_a, time_step_mask_b, time_step_mask_c)\n",
        "\n",
        "    # Concatenate the Cross-attention outputs\n",
        "    combined = tf.concat([cross_a, cross_b, cross_c], axis=2)\n",
        "    combined = Dense(ff_dim, activation='relu')(combined)\n",
        "    combined = Dropout(dropout)(combined)\n",
        "    encoder_output = LayerNormalization(epsilon=1e-6)(combined)\n",
        "\n",
        "    # Decoder (predicting next two time points)\n",
        "    # Decoder input\n",
        "    decoder_inputs = Input(shape=(2, dim_a+dim_b+dim_c))\n",
        "    decoder_inputs += pe(2, dim_a+dim_b+dim_c)\n",
        "    decoder_outputs = transformer_decoder(decoder_inputs, encoder_output, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = TimeDistributed(Dense(dim_a+dim_b+dim_c))(decoder_outputs)\n",
        "\n",
        "    # CAAT-EHR Model\n",
        "    model = Model([encoder_input_a, encoder_input_b, encoder_input_c, decoder_inputs], outputs)\n",
        "    # CAAT-EHR encoder Model\n",
        "    encoder = Model([encoder_input_a, encoder_input_b, encoder_input_c], encoder_output, name='encoder')\n",
        "\n",
        "    return model, encoder\n"
      ],
      "metadata": {
        "id": "4tU_hK4zpcjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retrieve the data**"
      ],
      "metadata": {
        "id": "uRdY9DfqsthB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# unpikle data\n",
        "file_name = 'modal1.pkl'\n",
        "X_pretrain_modal1 = pd.read_pickle(file_name)\n",
        "\n",
        "file_name = 'modal2.pkl'\n",
        "X_pretrain_modal2 = pd.read_pickle(file_name)\n",
        "\n",
        "file_name = 'modal3.pkl'\n",
        "X_pretrain_modal3 = pd.read_pickle(file_name)\n",
        "\n",
        "file_name = 'target.pkl'\n",
        "pretrain_target = pd.read_pickle(file_name)\n"
      ],
      "metadata": {
        "id": "R1lEX9iNpclx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_pretrain_modal1.shape"
      ],
      "metadata": {
        "id": "kViQVJW_pcoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_pretrain_modal2.shape"
      ],
      "metadata": {
        "id": "lUFpqYVtpcrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_pretrain_modal3.shape"
      ],
      "metadata": {
        "id": "cTCHCxSppctu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrain_target.shape"
      ],
      "metadata": {
        "id": "fr3FnfvVpcwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameters**"
      ],
      "metadata": {
        "id": "uya0tjI9tl_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "MAX_SEQ_LENGTH = 14  # Maximum sequence length\n",
        "INPUT_DIM_1 = 12\n",
        "INPUT_DIM_2 = 7\n",
        "INPUT_DIM_3 = 64\n",
        "HEAD_SIZE = 32\n",
        "NUM_HEADS = 2\n",
        "FF_DIM = 64\n",
        "DROPOUT_RATE = 0.1\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "LEARNING_RATE = 1e-4\n",
        "\n"
      ],
      "metadata": {
        "id": "bsQvVNPJpcy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building the model**"
      ],
      "metadata": {
        "id": "8feFTr4Kt9lI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and compile the model\n",
        "model, encoder_model = build_transformer_model(MAX_SEQ_LENGTH, INPUT_DIM_1, INPUT_DIM_2, INPUT_DIM_3, HEAD_SIZE, NUM_HEADS, FF_DIM, DROPOUT_RATE)\n",
        "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=optimizer, loss='mse')\n"
      ],
      "metadata": {
        "id": "orWccNZcpc1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-train the model**"
      ],
      "metadata": {
        "id": "5unQXlbRuFIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=20, mode=\"min\")\n",
        "history = model.fit([X_pretrain_modal1, X_pretrain_modal2, X_pretrain_modal3, pretrain_target], (pretrain_target), batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
        "                    callbacks=[callback])\n"
      ],
      "metadata": {
        "id": "gbVEGvxYpc4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save and load the model**"
      ],
      "metadata": {
        "id": "dAew6vf4uMoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model.save('transformer_encoder.keras')"
      ],
      "metadata": {
        "id": "yWTfpXRupc6p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}